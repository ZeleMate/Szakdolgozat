{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 1. K√ñRNYEZET BE√ÅLL√çT√ÅSA ===\n",
        "# K√∂nyvt√°rak telep√≠t√©se √©s import√°l√°sa\n",
        "%pip install -U torch sentence-transformers accelerate pyarrow pandas tqdm transformers runpod python-dotenv\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import json\n",
        "import pyarrow.parquet as pq\n",
        "import torch\n",
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "from typing import List\n",
        "from pathlib import Path\n",
        "import os\n",
        "import runpod\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# .env f√°jl bet√∂lt√©se a RUNPOD_API_KEY bet√∂lt√©s√©hez\n",
        "load_dotenv()\n",
        "\n",
        "# GPU-specifikus optimaliz√°ci√≥k m√°r nem sz√ºks√©gesek, mivel a sz√°m√≠t√°s a felh≈ëben t√∂rt√©nik\n",
        "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "# torch.backends.cudnn.benchmark = True\n",
        "# torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "print(f\"CUDA el√©rhet≈ë lok√°lisan: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 2. KONFIGUR√ÅCI√ì ===\n",
        "# RunPod Serverless API-hoz igaz√≠tott konfigur√°ci√≥.\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# API kulcs √©s Endpoint ID beolvas√°sa\n",
        "RUNPOD_API_KEY = os.getenv(\"RUNPOD_API_KEY\")\n",
        "RUNPOD_ENDPOINT_ID = \"5hjxb1eht972gw\" # A RunPod UI-b√≥l kim√°solt endpoint ID\n",
        "\n",
        "if not RUNPOD_API_KEY:\n",
        "    raise ValueError(\"A RUNPOD_API_KEY k√∂rnyezeti v√°ltoz√≥ nincs be√°ll√≠tva! √Åll√≠tsd be egy .env f√°jlban.\")\n",
        "\n",
        "# Bemeneti √©s kimeneti f√°jlok\n",
        "INPUT_CSV_PATH = Path(\"../processed_data/cleaned_data_for_embedding.csv\")\n",
        "OUTPUT_PARQUET_PATH = Path(\"../processed_data/documents_with_embeddings_api.parquet\")\n",
        "\n",
        "# Embedding √©s batch m√©ret be√°ll√≠t√°sok\n",
        "EMBEDDING_DIMENSION = 1024\n",
        "# Kliens oldali batch m√©ret, egy k√©r√©sben ennyi sz√∂veg megy el az API-nak\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "print(f\"RunPod Endpoint ID: {RUNPOD_ENDPOINT_ID}\")\n",
        "print(f\"Input: {INPUT_CSV_PATH}\")\n",
        "print(f\"Output: {OUTPUT_PARQUET_PATH}\")\n",
        "print(f\"Batch m√©ret: {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 3. EMBEDDING GENER√ÅTOR OSZT√ÅLY (RUNPOD API) ===\n",
        "class EmbeddingGeneratorAPI:\n",
        "    def __init__(self, api_key: str, endpoint_id: str, batch_size: int, dimension: int):\n",
        "        self.api_key = api_key\n",
        "        self.endpoint_id = endpoint_id\n",
        "        self.batch_size = batch_size\n",
        "        self.dimension = dimension\n",
        "        runpod.api_key = self.api_key\n",
        "        self.endpoint = runpod.Endpoint(self.endpoint_id)\n",
        "        print(f\"RunPod API gener√°tor inicializ√°lva a(z) '{self.endpoint_id}' endpoint-ra.\")\n",
        "\n",
        "    def load_model(self):\n",
        "        # Nincs sz√ºks√©g modell bet√∂lt√©s√©re, az endpoint kezeli.\n",
        "        # Ez a met√≥dus a kompatibilit√°s miatt marad.\n",
        "        print(\"A modell a RunPod szerveren fut, nincs sz√ºks√©g lok√°lis bet√∂lt√©sre.\")\n",
        "\n",
        "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
        "        all_embeddings = []\n",
        "        \n",
        "        # Feldolgoz√°s batch-ekben\n",
        "        for i in tqdm(range(0, len(texts), self.batch_size), desc=\"Embedding gener√°l√°s (API)\"):\n",
        "            batch_texts = texts[i:i + self.batch_size]\n",
        "            \n",
        "            request = {\n",
        "                \"input\": {\n",
        "                    \"texts\": batch_texts,\n",
        "                    \"normalize_embeddings\": True\n",
        "                }\n",
        "            }\n",
        "            \n",
        "            try:\n",
        "                # Szinkron k√©r√©s k√ºld√©se, ami megv√°rja a v√°laszt\n",
        "                result = self.endpoint.run_sync(request, timeout=600) # 10 perc timeout\n",
        "                batch_embeddings = result['output']['embeddings']\n",
        "                all_embeddings.extend(batch_embeddings)\n",
        "            except Exception as e:\n",
        "                print(f\"Hiba a RunPod API h√≠v√°s sor√°n a(z) {i}-edik elemn√©l: {e}\")\n",
        "                # Hibakezel√©s: √ºres embeddingekkel t√∂ltj√ºk fel a hib√°s batch hely√©t\n",
        "                error_placeholder = np.zeros((len(batch_texts), self.dimension), dtype=np.float32)\n",
        "                all_embeddings.extend(error_placeholder.tolist())\n",
        "                continue\n",
        "        \n",
        "        embeddings_array = np.array(all_embeddings, dtype=np.float32)\n",
        "\n",
        "        # Biztons√°gi ellen≈ërz√©s a dimenzi√≥ra\n",
        "        if embeddings_array.shape[1] != self.dimension:\n",
        "             print(f\"Figyelmeztet√©s: V√°ratlan embedding dimenzi√≥: {embeddings_array.shape[1]}. Korrekci√≥ {self.dimension}-ra.\")\n",
        "             # Itt vagy hib√°t dobunk, vagy megpr√≥b√°ljuk korrig√°lni, ha lehets√©ges\n",
        "             # Most felt√©telezz√ºk, hogy ez egy kritikus hiba\n",
        "             raise ValueError(f\"V√°ratlan embedding dimenzi√≥: {embeddings_array.shape[1]}\")\n",
        "            \n",
        "        return embeddings_array\n",
        "\n",
        "    def _cleanup_memory(self):\n",
        "        # Nincs sz√ºks√©g GPU mem√≥ria takar√≠t√°s√°ra\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 4. F≈ê FELDOLGOZ√ÅSI FOLYAMAT ===\n",
        "def create_metadata_json(row: pd.Series) -> str:\n",
        "    \"\"\"L√©trehoz egy JSON stringet a sor metaadataib√≥l.\"\"\"\n",
        "    metadata_cols = [col for col in row.index if col not in ['text', 'embedding']]\n",
        "    metadata_dict = row[metadata_cols].dropna().to_dict()\n",
        "    return json.dumps({k: str(v) for k, v in metadata_dict.items()}, ensure_ascii=False)\n",
        "\n",
        "def main():\n",
        "    print(\"Feldolgoz√°s ind√≠t√°sa a RunPod API-val...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Bemeneti adatok beolvas√°sa\n",
        "    if not INPUT_CSV_PATH.exists():\n",
        "        raise FileNotFoundError(f\"Hiba: A bemeneti f√°jl nem tal√°lhat√≥: {INPUT_CSV_PATH}\")\n",
        "    \n",
        "    print(f\"Bemeneti CSV beolvas√°sa: {INPUT_CSV_PATH}\")\n",
        "    # Egyszer≈±s√≠tett beolvas√°s, a C motor haszn√°lat√°val\n",
        "    df = pd.read_csv(INPUT_CSV_PATH)\n",
        "    print(f\"{len(df):,} sor sikeresen beolvasva.\")\n",
        "\n",
        "    # Sz√∂vegek kinyer√©se\n",
        "    df['text'] = df['text'].fillna('')\n",
        "    texts_to_process = df['text'].astype(str).tolist()\n",
        "    \n",
        "    if not texts_to_process:\n",
        "        print(\"Nincs feldolgozand√≥ sz√∂veg a bemeneti f√°jlban.\")\n",
        "        return\n",
        "\n",
        "    # Embedding gener√°tor inicializ√°l√°sa √©s \"modell bet√∂lt√©se\"\n",
        "    generator = EmbeddingGeneratorAPI(RUNPOD_API_KEY, RUNPOD_ENDPOINT_ID, BATCH_SIZE, EMBEDDING_DIMENSION)\n",
        "    generator.load_model() # Kompatibilit√°si h√≠v√°s, val√≥j√°ban nem csin√°l semmit\n",
        "\n",
        "    # Embedding gener√°l√°s a teljes adathalmazon\n",
        "    print(\"Embedding gener√°l√°s megkezd√©se a RunPod API-n kereszt√ºl...\")\n",
        "    embeddings = generator.generate_embeddings(texts_to_process)\n",
        "    \n",
        "    # Mem√≥ria takar√≠t√°s a nagy m≈±velet ut√°n\n",
        "    generator._cleanup_memory()\n",
        "\n",
        "    # Eredm√©nyek hozz√°ad√°sa a DataFrame-hez\n",
        "    if len(embeddings) == len(df):\n",
        "        df['embedding'] = list(embeddings)\n",
        "    else:\n",
        "        print(f\"KRITIKUS HIBA: Az embeddingek sz√°ma ({len(embeddings)}) nem egyezik a DataFrame sorainak sz√°m√°val ({len(df)}). A program le√°ll.\")\n",
        "        return\n",
        "\n",
        "    # Metaadatok gener√°l√°sa\n",
        "    print(\"Metaadat JSON gener√°l√°sa...\")\n",
        "    df['metadata_json'] = [create_metadata_json(row) for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Metaadat JSON\")]\n",
        "\n",
        "    # Kimeneti DataFrame √©s ment√©s Parquet form√°tumba\n",
        "    final_df = df[['doc_id', 'text', 'embedding', 'metadata_json']]\n",
        "    OUTPUT_PARQUET_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Eredm√©nyek ment√©se a Parquet f√°jlba: {OUTPUT_PARQUET_PATH}\")\n",
        "    final_df.to_parquet(OUTPUT_PARQUET_PATH, index=False, compression='snappy')\n",
        "    \n",
        "    # √ñsszegz√©s\n",
        "    total_rows_processed = len(final_df)\n",
        "    total_time_seconds = time.time() - start_time\n",
        "    rows_per_second = total_rows_processed / total_time_seconds if total_time_seconds > 0 else 0\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"‚úÖ FELDOLGOZ√ÅS BEFEJEZVE\")\n",
        "    print(f\"üìÑ Kimeneti f√°jl: {OUTPUT_PARQUET_PATH}\")\n",
        "    print(f\"‚è±Ô∏è Teljes id≈ë: {total_time_seconds:.2f} m√°sodperc ({total_time_seconds / 60:.2f} perc)\")\n",
        "    print(f\"üìä Feldolgozott sorok: {total_rows_processed:,}\")\n",
        "    print(f\"‚ö° √Åtlagos sebess√©g: {rows_per_second:.2f} sor/mp\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "# F≈ë folyamat futtat√°sa\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 5. VALID√ÅCI√ì ===\n",
        "print(\"Kimeneti Parquet f√°jl valid√°l√°sa...\")\n",
        "\n",
        "if OUTPUT_PARQUET_PATH.exists():\n",
        "    try:\n",
        "        parquet_file = pq.ParquetFile(OUTPUT_PARQUET_PATH)\n",
        "        file_num_rows = parquet_file.metadata.num_rows\n",
        "        file_size_mb = OUTPUT_PARQUET_PATH.stat().st_size / (1024 * 1024)\n",
        "        \n",
        "        df_sample = pd.read_parquet(OUTPUT_PARQUET_PATH, engine='pyarrow').head(5)\n",
        "        sample_embedding = df_sample['embedding'].iloc[0]\n",
        "        \n",
        "        print(\"\\n‚úÖ VALID√ÅCI√ì SIKERES!\")\n",
        "        print(f\"  F√°jl m√©ret: {file_size_mb:.2f} MB\")\n",
        "        print(f\"  Sorok sz√°ma: {file_num_rows:,}\")\n",
        "        print(f\"  Oszlopok: {df_sample.columns.tolist()}\")\n",
        "        print(f\"  Els≈ë embedding dimenzi√≥ja: {len(sample_embedding)}\")\n",
        "        print(\"\\n--- Minta Adatsor ---\")\n",
        "        display(df_sample)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Hiba a Parquet f√°jl valid√°l√°sa k√∂zben: {e}\")\n",
        "        print(f\"\\n‚ùå HIBA a valid√°ci√≥ sor√°n: {e}\")\n",
        "else:\n",
        "    print(\"A kimeneti Parquet f√°jl nem j√∂tt l√©tre.\")\n",
        "    print(\"\\n‚ùå HIBA: A kimeneti f√°jl nem tal√°lhat√≥!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "courtrankrl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
