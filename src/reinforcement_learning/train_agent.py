"""
Script to train the RL ranking agent using expert evaluations.
This script now uses the self-contained RankingEnv and loads all data from Azure.
"""
import sys
from pathlib import Path
import numpy as np
import pandas as pd
from typing import List, Dict, Any
import io
import logging

# Add project root to sys.path
project_root = Path(__file__).resolve().parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.reinforcement_learning.agent import RLAgent
from src.reinforcement_learning.environment import RankingEnv
from src.reinforcement_learning.reward_models.reward import compute_ndcg
from src.utils.azure_blob_storage import AzureBlobStorage
from configs import config
from tqdm import tqdm

# --- Be√°ll√≠t√°sok ---
TRAINING_ITERATIONS = 1000
BATCH_SIZE = 32
INITIAL_TOP_K = 20 # Ennek meg kell egyeznie a RankingEnv-ben haszn√°lt √©rt√©kkel

# Loggol√°s be√°ll√≠t√°sa
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_expert_evaluations_from_azure(blob_storage: AzureBlobStorage) -> pd.DataFrame:
    """Loads expert evaluation data from a CSV in Azure Blob Storage."""
    logging.info(f"Szak√©rt≈ëi √©rt√©kel√©sek let√∂lt√©se: {config.BLOB_EXPERT_EVALUATIONS_CSV}")
    try:
        data = blob_storage.download_data(config.BLOB_EXPERT_EVALUATIONS_CSV)
        df = pd.read_csv(io.BytesIO(data))
        logging.info(f"‚úÖ Sikeresen bet√∂ltve {len(df)} √©rt√©kel√©s.")
        return df
    except Exception as e:
        logging.error(f"Hiba a szak√©rt≈ëi √©rt√©kel√©sek let√∂lt√©sekor: {e}", exc_info=True)
        return pd.DataFrame()

def get_relevance_scores(ranked_doc_ids: List[str], eval_df: pd.DataFrame, query: str) -> List[float]:
    """Retrieves relevance scores for a ranked list of document IDs."""
    query_evals = eval_df[eval_df['query'] == query].set_index('doc_id')
    return [query_evals.loc[doc_id, 'relevance'] if doc_id in query_evals.index else 0.0 for doc_id in ranked_doc_ids]

def main():
    """Main training loop for the RL agent."""
    logging.info("üöÄ RL √úGYN√ñK TAN√çT√ÅS√ÅNAK IND√çT√ÅSA")

    # 1. Er≈ëforr√°sok inicializ√°l√°sa
    try:
        blob_storage = AzureBlobStorage(container_name=config.AZURE_CONTAINER_NAME)
        env = RankingEnv(initial_top_k=INITIAL_TOP_K)
        
        agent_input_dim = env.observation_space.shape[0]
        agent_output_dim = env.action_space.shape[0]
        agent = RLAgent(input_dim=agent_input_dim, output_dim=agent_output_dim)
        # Pr√≥b√°ljuk bet√∂lteni a kor√°bban mentett modellt
        agent.load()

    except Exception as e:
        logging.error(f"Hiba az inicializ√°l√°s sor√°n: {e}", exc_info=True)
        sys.exit(1)

    # 2. Szak√©rt≈ëi √©rt√©kel√©sek bet√∂lt√©se
    eval_df = load_expert_evaluations_from_azure(blob_storage)
    if eval_df.empty:
        logging.error("Nincsenek szak√©rt≈ëi √©rt√©kel√©sek, a tan√≠t√°s le√°ll.")
        sys.exit(1)
    
    queries_with_evals = eval_df['query'].unique().tolist()
    logging.info(f"Tan√≠t√°s {len(queries_with_evals)} egyedi lek√©rdez√©s alapj√°n.")

    # 3. Tan√≠t√°si ciklus
    for iteration in tqdm(range(TRAINING_ITERATIONS), desc="Training Iterations"):
        experience_batch: List[Dict[str, Any]] = []
        
        # Tapasztalatgy≈±jt√©s a batch-hez
        for _ in range(BATCH_SIZE):
            query = np.random.choice(queries_with_evals)
            state, info = env.reset(query=query)
            
            # Akci√≥ v√°laszt√°sa az √°genst≈ël
            action = agent.select_action(state)
            
            # L√©p√©s a k√∂rnyezetben (a jutalom itt m√©g placeholder)
            next_state, _, done, _, step_info = env.step(action)
            
            # Jutalom sz√°m√≠t√°sa
            reranked_results = step_info['reranked_results']
            reranked_doc_ids = [res.doc_id for res in reranked_results]
            
            relevance_scores = get_relevance_scores(reranked_doc_ids, eval_df, query)
            reward = compute_ndcg(np.array(relevance_scores))

            experience_batch.append({
                "state": state,
                "action": action,
                "reward": reward
            })

        if not experience_batch:
            logging.warning("Nem siker√ºlt tapasztalatot gy≈±jteni, a friss√≠t√©s kimarad.")
            continue
            
        # √Ågens friss√≠t√©se a gy≈±jt√∂tt tapasztalatok alapj√°n
        agent.update(experience_batch)

        if (iteration + 1) % 10 == 0:
            avg_reward = np.mean([exp['reward'] for exp in experience_batch])
            tqdm.write(f"Iter√°ci√≥ {iteration+1}/{TRAINING_ITERATIONS} | √Åtlagos jutalom (NDCG): {avg_reward:.4f}")

        # Modell ment√©se id≈ënk√©nt
        if (iteration + 1) % 100 == 0:
            agent.save()
            logging.info(f"√úgyn√∂k mentve a(z) {iteration+1}. iter√°ci√≥n√°l.")

    # V√©gs≈ë modell ment√©se
    agent.save()
    logging.info("üéâ Tan√≠t√°s befejezve. A v√©gs≈ë modell mentve.")

if __name__ == "__main__":
    main()
