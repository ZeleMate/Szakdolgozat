# src/data_loader/build_faiss_index.py
"""
FAISS index √©p√≠t≈ë szkript a dokumentum embeddingek alapj√°n.
Beolvassa az embeddingeket tartalmaz√≥ Parquet f√°jlt az Azure Blob Storage-b√≥l,
l√©trehozza a FAISS indexet √©s a hozz√° tartoz√≥ ID-lek√©pez√©st, majd felt√∂lti
azokat is a Blob Storage-ba.
"""
import pandas as pd
import numpy as np
import faiss
import logging
import sys
import gc
import time
import json
import io
from pathlib import Path
from typing import Tuple, Dict, Any, List

# Projekt gy√∂k√©rk√∂nyvt√°r√°nak hozz√°ad√°sa a Python √∫tvonalhoz
project_root = Path(__file__).resolve().parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# Konfigur√°ci√≥ √©s seg√©dprogramok import√°l√°sa
try:
    from configs import config
    from src.utils.azure_blob_storage import AzureBlobStorage
except ImportError as e:
    print(f"HIBA: Modul import√°l√°sa sikertelen: {e}")
    sys.exit(1)

# Loggol√°s be√°ll√≠t√°sa
logging.basicConfig(level=config.LOGGING_LEVEL, format=config.LOGGING_FORMAT)

def create_faiss_index(vectors: np.ndarray, vector_count: int) -> Any:
    """
    L√©trehoz egy FAISS indexet a megadott vektorokb√≥l.
    A vektorok sz√°ma alapj√°n v√°laszt IndexFlatL2 vagy IndexIVFFlat t√≠pust.
    """
    vector_dimension = vectors.shape[1]
    logging.info(f"FAISS index l√©trehoz√°sa {vector_count} vektorral, dimenzi√≥: {vector_dimension}")
    
    if not vectors.flags.c_contiguous:
        logging.warning("A bemeneti vektorok nem C-folyamatosak, √°talak√≠t√°s...")
        vectors = np.ascontiguousarray(vectors, dtype=np.float32)
    
    # Kisebb adathalmazokhoz a IndexFlatL2 gyorsabb √©s egyszer≈±bb.
    # A training l√©p√©st is kihagyhatjuk.
    # Nagyobb adathalmazokn√°l az IndexIVFFlat gyorsabb keres√©st tesz lehet≈ëv√© a particion√°l√°s miatt.
    nlist = 100 # A particion√°l√°s (klaszterek) sz√°ma
    if vector_count < 10000:
        logging.info(f"Kis adathalmaz ({vector_count} vektor), IndexFlatL2 haszn√°lata.")
        index = faiss.IndexFlatL2(vector_dimension)
    else:
        logging.info(f"Nagyobb adathalmaz ({vector_count} vektor), IndexIVFFlat l√©trehoz√°sa {nlist} klaszterrel.")
        quantizer = faiss.IndexFlatL2(vector_dimension)
        index = faiss.IndexIVFFlat(quantizer, vector_dimension, nlist, faiss.METRIC_L2)
        
        logging.info("IndexIVFFlat betan√≠t√°sa...")
        if not index.is_trained and vector_count > 0:
            index.train(vectors)
        else:
            logging.info("Az index m√°r betan√≠tott vagy nincs adat a tan√≠t√°shoz.")
            
        index.nprobe = 10 # H√°ny klasztert vizsg√°ljon keres√©skor
    
    logging.info("Vektorok hozz√°ad√°sa az indexhez...")
    start_time = time.time()
    if vector_count > 0:
        index.add(vectors)
    else:
        logging.warning("Nincsenek vektorok az indexhez ad√°shoz.")
    logging.info(f"Vektorok indexel√©se befejezve. Feldolgozott vektorok: {index.ntotal}, id≈ë: {time.time() - start_time:.2f} mp")
    
    return index

def test_search(index: Any, vectors: np.ndarray, id_mapping: Dict[int, Any], k: int = 5) -> None:
    """
    Leteszteli a FAISS indexet egy egyszer≈± keres√©ssel az els≈ë vektor alapj√°n.
    """
    if vectors.shape[0] == 0:
        logging.warning("Nincsenek vektorok a keres√©s tesztel√©s√©hez.")
        return

    logging.info(f"FAISS index tesztel√©se: {k} legk√∂zelebbi szomsz√©d keres√©se az els≈ë vektorhoz...")
    query_vector = np.ascontiguousarray(vectors[0:1], dtype=np.float32)
    
    start_time = time.time()
    distances, indices = index.search(query_vector, k)
    search_time = time.time() - start_time
    
    logging.info(f"Keres√©si id≈ë: {search_time*1000:.2f} ms")
    if indices.size > 0:
        logging.info(f"Tal√°latok FAISS indexei: {indices[0].tolist()}")
        try:
            # Fontos: Az id_mapping kulcsai int-ek, a keres√©s eredm√©nye (indices) int64 lehet.
            doc_ids = [id_mapping[int(idx)] for idx in indices[0].tolist() if int(idx) in id_mapping]
            logging.info(f"Tal√°latok eredeti dokumentum ID-jai: {doc_ids}")
        except KeyError as e:
            logging.error(f"Hiba a dokumentum ID-k visszakeres√©sekor a lek√©pez√©sb≈ël: hi√°nyz√≥ FAISS index {e}")
    else:
        logging.info("A tesztkeres√©s nem adott vissza tal√°latot.")

def main():
    """ F≈ë f√ºggv√©ny a FAISS index l√©trehoz√°s√°hoz Azure Blob Storage integr√°ci√≥val. """
    logging.info("üöÄ FAISS INDEX √âP√çT√âSE AZURE BLOB STORAGE ALAPJ√ÅN")
    
    # Azure Blob Storage kliens inicializ√°l√°sa
    try:
        blob_storage = AzureBlobStorage(container_name=config.AZURE_CONTAINER_NAME)
    except ValueError as e:
        logging.error(e)
        sys.exit(1)

    # ===== 1. ADATOK LET√ñLT√âSE AZURE-B√ìL =====
    input_blob_path = config.BLOB_DOCUMENTS_WITH_EMBEDDINGS_PARQUET
    logging.info(f"Embeddingek let√∂lt√©se: {input_blob_path}")
    try:
        data = blob_storage.download_data(input_blob_path)
        df = pd.read_parquet(io.BytesIO(data))
        logging.info(f"‚úÖ Sikeresen let√∂ltve √©s beolvasva {len(df):,} dokumentum.")
    except Exception as e:
        logging.error(f"Hiba az embeddingek let√∂lt√©se vagy feldolgoz√°sa k√∂zben: {e}", exc_info=True)
        sys.exit(1)

    try:
        # ===== 2. ADATOK VALID√ÅL√ÅSA √âS TISZT√çT√ÅSA =====
        logging.info(f"Adatok valid√°l√°sa...")
        
        if 'embedding' not in df.columns or 'doc_id' not in df.columns:
            logging.error("A DataFrame nem tartalmazza a sz√ºks√©ges 'embedding' vagy 'doc_id' oszlopot.")
            sys.exit(1)

        missing_count = df['embedding'].isna().sum()
        if missing_count:
            logging.warning(f"{missing_count} sorban nincs embedding, ezek kisz≈±r√©se...")
            df = df.dropna(subset=['embedding']).reset_index(drop=True)
        
        if df.empty:
            logging.error("Nincsenek √©rv√©nyes embeddingek az index √©p√≠t√©s√©hez.")
            sys.exit(1)
        
        logging.info(f"Valid√°l√°s ut√°n maradt {len(df):,} dokumentum.")

        # ===== 3. VEKTOROK √âS ID-LEK√âPEZ√âS L√âTREHOZ√ÅSA =====
        logging.info("Vektorok √©s ID-lek√©pez√©s el≈ëk√©sz√≠t√©se...")
        
        # A vektorokat egyetlen NumPy t√∂mbbe f≈±zz√ºk
        vectors = np.vstack(df['embedding'].values).astype('float32')
        
        # Ellen≈ërizz√ºk a dimenzi√≥t
        if vectors.shape[1] != config.EMBEDDING_DIMENSION:
            logging.error(
                f"Embedding dimenzi√≥ elt√©r√©s: "
                f"V√°rt: {config.EMBEDDING_DIMENSION}, Kapott: {vectors.shape[1]}"
            )
            sys.exit(1)
        
        # ID-lek√©pez√©s l√©trehoz√°sa: FAISS index -> eredeti doc_id
        # A FAISS egyszer≈±, 0-t√≥l n-1-ig terjed≈ë indexeket haszn√°l.
        id_mapping = {i: doc_id for i, doc_id in enumerate(df['doc_id'])}
        vector_count = len(df)
        
        del df; gc.collect()

        # ===== 4. FAISS INDEX L√âTREHOZ√ÅSA =====
        index = create_faiss_index(vectors, vector_count)

        # ===== 5. TESZTEL√âS =====
        test_search(index, vectors, id_mapping)
        del vectors; gc.collect()

        # ===== 6. INDEX √âS LEK√âPEZ√âS FELT√ñLT√âSE AZURE-BA =====
        # FAISS index ment√©se mem√≥ri√°ba √©s felt√∂lt√©se
        logging.info(f"FAISS index felt√∂lt√©se ide: {config.BLOB_FAISS_INDEX}")
        index_buffer = io.BytesIO()
        faiss.write_index(index, faiss.PyCallbackIOWriter(index_buffer.write))
        blob_storage.upload_data(index_buffer.getvalue(), config.BLOB_FAISS_INDEX)
        logging.info("‚úÖ FAISS index sikeresen felt√∂ltve.")

        # ID-lek√©pez√©s ment√©se JSON-k√©nt √©s felt√∂lt√©se
        logging.info(f"ID-lek√©pez√©s felt√∂lt√©se ide: {config.BLOB_FAISS_DOC_ID_MAP}")
        map_buffer = io.BytesIO(json.dumps(id_mapping, ensure_ascii=False).encode('utf-8'))
        blob_storage.upload_data(map_buffer.getvalue(), config.BLOB_FAISS_DOC_ID_MAP)
        logging.info("‚úÖ ID-lek√©pez√©s sikeresen felt√∂ltve.")

    except Exception as e:
        logging.error(f"V√°ratlan hiba t√∂rt√©nt az index √©p√≠t√©se sor√°n: {e}", exc_info=True)
        sys.exit(1)

    logging.info("\nüéâ FAISS INDEX √âP√çT√âS BEFEJEZVE!")

if __name__ == '__main__':
    main()