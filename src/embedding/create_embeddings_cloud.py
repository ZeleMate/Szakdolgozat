# src/embedding/create_embeddings_cloud.py

# ==============================================================================
# === 1. CSOMAGOK TELEP√çT√âSE ===
# ==============================================================================
# Futtassa ezt a cell√°t a sz√ºks√©ges csomagok telep√≠t√©s√©hez a Jupyter/Colab k√∂rnyezetben.
import sys
import subprocess

# A linter-bar√°t megold√°s a csomagok telep√≠t√©s√©re
packages = [
    "pandas", "numpy", "torch", "tqdm", "sentence-transformers",
    "langchain", "pyarrow", "azure-storage-blob", "python-dotenv"
]
try:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", *packages])
except subprocess.CalledProcessError as e:
    print(f"Hiba a csomagok telep√≠t√©se k√∂zben: {e}")

# ==============================================================================
# === 2. IMPORT√ÅL√ÅSOK √âS ALAPVET≈ê BE√ÅLL√çT√ÅSOK ===
# ==============================================================================
import pandas as pd
import numpy as np
import gc
import torch
import time
import os
import sys
import tempfile
import shutil
import io
from tqdm.auto import tqdm
from pathlib import Path
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
from azure.storage.blob import BlobServiceClient
from dotenv import load_dotenv

# ==============================================================================
# === 3. KONFIGUR√ÅCI√ìS V√ÅLTOZ√ìK ===
# ==============================================================================
# Helyi importok helyett itt defini√°ljuk a sz√ºks√©ges be√°ll√≠t√°sokat.

# --- Azure Blob Storage be√°ll√≠t√°sok ---
# FONTOS: Futtat√°s el≈ëtt gy≈ëz≈ëdj√∂n meg r√≥la, hogy az `AZURE_CONNECTION_STRING`
# k√∂rnyezeti v√°ltoz√≥ be van √°ll√≠tva a notebook k√∂rnyezet√©ben (pl. secrets)!
load_dotenv()
AZURE_CONTAINER_NAME = "courtrankrl"

# --- Blob Storage el√©r√©si utak ---
BLOB_PROCESSED_DATA_DIR = "processed"
BLOB_EMBEDDING_DIR = "embeddings"
BLOB_CLEANED_DOCUMENTS_PARQUET = f"{BLOB_PROCESSED_DATA_DIR}/cleaned_documents.parquet"
BLOB_DOCUMENTS_WITH_EMBEDDINGS_PARQUET = f"{BLOB_EMBEDDING_DIR}/documents_with_embeddings.parquet"

# --- Modell √©s darabol√°s be√°ll√≠t√°sok ---
MODEL_NAME = "Qwen/Qwen3-Embedding-0.6B"
BATCH_SIZE = 512
CHUNK_SIZE = 8000
CHUNK_OVERLAP = 200

# --- Ideiglenes f√°jlok ---
TEMP_DATA_DIR = Path("temp_data")

# ==============================================================================
# === 4. AZURE BLOB STORAGE SEG√âDOSZT√ÅLY ===
# ==============================================================================
# A kor√°bbi src.utils.azure_blob_storage.py tartalma be√°gyazva.

class AzureBlobStorage:
    def __init__(self, container_name: str):
        self.connection_string = os.getenv("AZURE_CONNECTION_STRING")
        if not self.connection_string:
            raise ValueError("AZURE_CONNECTION_STRING k√∂rnyezeti v√°ltoz√≥ nincs be√°ll√≠tva.")
        self.container_name = container_name
        self.blob_service_client = BlobServiceClient.from_connection_string(self.connection_string)
        self.container_client = self.blob_service_client.get_container_client(container_name)
        if not self.container_client.exists():
            self.container_client.create_container()

    def upload_data(self, data: bytes, blob_path: str):
        """Uploads in-memory data (bytes) to Azure Blob Storage."""
        blob_client = self.blob_service_client.get_blob_client(container=self.container_name, blob=blob_path)
        blob_client.upload_blob(data, overwrite=True)
        print(f"Uploaded data to {self.container_name}/{blob_path}")

    def download_data(self, blob_path: str) -> bytes:
        """Downloads a file from Azure Blob Storage as bytes."""
        blob_client = self.blob_service_client.get_blob_client(container=self.container_name, blob=blob_path)
        return blob_client.download_blob().readall()

# ==============================================================================
# === 5. FELDOLGOZ√ì OSZT√ÅLYOK ===
# ==============================================================================

class DocumentProcessor:
    """Felel≈ës egy dokumentum sz√∂veg√©nek darabol√°s√°√©rt (chunking)."""
    def __init__(self, chunk_size, chunk_overlap):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            is_separator_regex=False
        )
    def split_document(self, doc_id, text):
        if not isinstance(text, str) or not text.strip():
            return []
        chunks_text = self.text_splitter.split_text(text)
        return [{'doc_id': doc_id, 'text_chunk': chunk} for chunk in chunks_text]

# ==============================================================================
# === 6. F≈ê VEZ√âRL≈ê LOGIKA ===
# ==============================================================================

def main():
    """F≈ë vez√©rl≈ë f√ºggv√©ny az embedding gener√°l√°shoz, t√∂bb GPU t√°mogat√°s√°val."""
    if not torch.cuda.is_available():
        print("‚ùå HIBA: CUDA nem el√©rhet≈ë. A szkript csak GPU-s k√∂rnyezetben futtathat√≥.")
        return
        
    num_gpus = torch.cuda.device_count()
    print(f"üî• {num_gpus} db GPU el√©rhet≈ë.")
    for i in range(num_gpus):
        print(f"  - GPU {i}: {torch.cuda.get_device_name(i)}")

    try:
        blob_storage = AzureBlobStorage(container_name=AZURE_CONTAINER_NAME)
    except ValueError as e:
        print(f"‚ùå Hiba az Azure kliens inicializ√°l√°sa k√∂zben: {e}")
        return

    # Helyi gyors√≠t√≥t√°r k√∂nyvt√°r kezel√©se
    TEMP_DATA_DIR.mkdir(exist_ok=True)
    print(f"üìÅ Ideiglenes adatok helye: {TEMP_DATA_DIR.resolve()}")
    
    model = None
    pool = None
    try:
        input_blob_path = BLOB_CLEANED_DOCUMENTS_PARQUET
        local_input_file = TEMP_DATA_DIR / Path(input_blob_path).name

        # Bemeneti f√°jl ellen≈ërz√©se √©s felt√©teles let√∂lt√©se
        if local_input_file.exists():
            print(f"‚úÖ Bemeneti f√°jl m√°r l√©tezik a helyi gyors√≠t√≥t√°rban: {local_input_file}")
        else:
            print(f"‚¨áÔ∏è Bemeneti adatok let√∂lt√©se: {input_blob_path} -> {local_input_file}")
            try:
                input_data = blob_storage.download_data(input_blob_path)
                with open(local_input_file, "wb") as f:
                    f.write(input_data)
                del input_data
                gc.collect()
                print("‚úÖ Let√∂lt√©s sikeres.")
            except Exception as e:
                print(f"‚ùå Hiba a let√∂lt√©s sor√°n: {e}")
                return
            
        print(f"\n--- Feldolgoz√°s ind√≠t√°sa {num_gpus} GPU-n ---")
        main_start_time = time.time()
        
        df_full = pd.read_parquet(local_input_file)
        
        if df_full.empty:
            print("‚ö†Ô∏è A bemeneti DataFrame √ºres, nincs mit feldolgozni.")
            return

        processor = DocumentProcessor(CHUNK_SIZE, CHUNK_OVERLAP)
        
        print("Sz√∂vegek darabol√°sa (chunking)...")
        all_chunk_records = []
        for _, row in tqdm(df_full.iterrows(), total=len(df_full), desc="Dokumentumok feldolgoz√°sa"):
            chunks = processor.split_document(row['doc_id'], row['text'])
            if chunks:
                meta_cols = {col: row.get(col) for col in df_full.columns if col != 'text'}
                for i, chunk_info in enumerate(chunks):
                    record = meta_cols.copy()
                    record['chunk_id'] = f"{chunk_info['doc_id']}-{i}"
                    record['text_chunk'] = chunk_info['text_chunk']
                    all_chunk_records.append(record)
        
        if not all_chunk_records:
            print("‚ö†Ô∏è A dokumentumokb√≥l nem siker√ºlt darabokat k√©sz√≠teni.")
            return

        print(f"√ñsszesen {len(all_chunk_records):,} darab (chunk) k√©sz√ºlt.")
        result_df = pd.DataFrame(all_chunk_records)
        del df_full, all_chunk_records
        gc.collect()

        print(f"Modell bet√∂lt√©se: {MODEL_NAME}...")
        model = SentenceTransformer(
            MODEL_NAME, 
            trust_remote_code=True,
            cache_folder=os.path.join(tempfile.gettempdir(), 'sentence_transformers_cache')
        )

        print("Embeddingek gener√°l√°sa...")
        text_chunks_list = result_df['text_chunk'].tolist()
        
        # T√∂bb GPU-s feldolgoz√°s ind√≠t√°sa
        target_devices = [f'cuda:{i}' for i in range(num_gpus)]
        pool = model.start_multi_process_pool(target_devices=target_devices)
        
        # Az encode_multi_process automatikusan mutatja a progress bart
        embeddings = model.encode_multi_process(
            text_chunks_list,
            pool=pool,
            batch_size=BATCH_SIZE
        )
        
        model.stop_multi_process_pool(pool)
        pool = None # Biztos√≠tjuk, hogy a finally blokk ne pr√≥b√°lja √∫jra le√°ll√≠tani

        result_df['embedding'] = list(embeddings.astype(np.float32))

        if 'text' in result_df.columns:
            result_df = result_df.drop(columns=['text'])

        print(f"‚¨ÜÔ∏è Feldolgozott adatok felt√∂lt√©se ({len(result_df):,} sor)...")
        output_blob_path = BLOB_DOCUMENTS_WITH_EMBEDDINGS_PARQUET
        
        buffer = io.BytesIO()
        result_df.to_parquet(buffer, index=False, engine='pyarrow', compression='snappy')
        buffer.seek(0)
        
        blob_storage.upload_data(data=buffer.getvalue(), blob_path=output_blob_path)
        
        print(f"‚úÖ Felt√∂lt√©s sikeres ide: {AZURE_CONTAINER_NAME}/{output_blob_path}")

        total_time = time.time() - main_start_time
        print(f"\n--- Feldolgoz√°s befejezve {total_time:.2f} m√°sodperc alatt ---")

    finally:
        print("üßπ Mem√≥ria felszabad√≠t√°sa...")
        if pool:
            model.stop_multi_process_pool(pool)
        if model:
            del model
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

# ==============================================================================
# === 7. SCRIPT FUTTAT√ÅSA ===
# ==============================================================================
# A szkript futtat√°s√°hoz h√≠vja meg a main() f√ºggv√©nyt a notebook egy cell√°j√°ban.
# A szkript v√©g√©n l√©v≈ë `main()` h√≠v√°s automatikusan lefut, amikor a teljes
# scriptet v√©grehajtja. Ha cell√°nk√©nt futtatja, ezt a h√≠v√°st hagyja a legv√©g√©re.
if __name__ == '__main__':
    main() 